\relax 
\citation{calsamiglia2009decentralizing}
\citation{calsamiglia2009decentralizing}
\citation{NY2017}
\citation{atlantic2016}
\citation{ProPublica2016}
\citation{ProPublica2016}
\citation{Ricci}
\citation{Loomis}
\citation{Loomis}
\citation{dwork2012fairness}
\citation{hebert2017calibration}
\citation{kearns2017preventing}
\citation{kim2018fairness}
\citation{dwork2014algorithmic}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{chouldechova2018frontiers}
\citation{hebert2017calibration}
\citation{kim2018fairness}
\citation{kearns2017preventing}
\citation{kearns2017preventing}
\citation{dwork2012fairness}
\citation{hebert2017calibration}
\citation{kim2018fairness}
\citation{kearns2017preventing}
\citation{hebert2017calibration}
\citation{kim2018fairness}
\citation{dwork2014algorithmic}
\citation{jagielski2018differentially}
\citation{foulds2018intersectional}
\citation{feldman2015certifying}
\citation{Loubes2018}
\citation{Loomis}
\citation{Ricci}
\citation{feldman2015certifying}
\citation{gretton2009covariate}
\citation{cortes2008sample}
\citation{feldman2015certifying}
\citation{Loubes2018}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: design}{{1}{3}}
\@writefile{toc}{\contentsline {paragraph}{Related Work}{3}}
\citation{ustun2018actionable}
\citation{russell2019efficient}
\@writefile{toc}{\contentsline {paragraph}{Contributions}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Individual and Multi-Differential Fairness}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Preliminary}{4}}
\@writefile{toc}{\contentsline {paragraph}{Notations}{4}}
\citation{dwork2014algorithmic}
\citation{jagielski2018differentially}
\citation{foulds2018intersectional}
\citation{dwork2012fairness}
\citation{chouldechova2018frontiers}
\@writefile{toc}{\contentsline {paragraph}{Assumptions}{5}}
\newlabel{ass: 1}{{1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Individual Differential Fairness}{5}}
\@writefile{toc}{\contentsline {paragraph}{Individual Differential Fairness}{5}}
\newlabel{def: idf}{{2.1}{5}}
\newlabel{eq: idf}{{1}{5}}
\@writefile{toc}{\contentsline {paragraph}{Differential Fairness and Distance of Distributions}{5}}
\newlabel{eq: maxdiv_idf}{{3}{5}}
\@writefile{toc}{\contentsline {paragraph}{Relation with Differential Privacy}{5}}
\citation{Ricci}
\citation{Loomis}
\citation{feldman2015certifying}
\citation{chouldechova2017fair}
\@writefile{toc}{\contentsline {paragraph}{Individual Fairness}{6}}
\@writefile{toc}{\contentsline {paragraph}{Intention in Disparate Treatment}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Multi-differential fairness}{6}}
\newlabel{def: mdf}{{2.2}{6}}
\newlabel{eq: mdf}{{4}{6}}
\@writefile{toc}{\contentsline {paragraph}{Disparate Treatment versus Disparate Impact}{6}}
\citation{kim2018fairness}
\citation{kearns2017preventing}
\citation{hebert2017calibration}
\@writefile{toc}{\contentsline {paragraph}{Collection of Indicators.}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Fairness Diagnostics}{7}}
\newlabel{eq: wvio}{{5}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Reduction to Agnostic Learning}{7}}
\@writefile{toc}{\contentsline {paragraph}{Multi Differential Fairness and Balanced Distribution}{7}}
\newlabel{eq: mdf_w}{{7}{8}}
\newlabel{eq: mdf_viol1}{{8}{8}}
\newlabel{eq: unfair}{{9}{8}}
\newlabel{lem: 1}{{3.1}{8}}
\citation{feldman2012agnostic}
\citation{kearns1994toward}
\citation{cortes2010learning}
\citation{rosenbaum1983central}
\citation{freedman2008weighting}
\citation{cortes2010learning}
\citation{gretton2009covariate}
\citation{cortes2008sample}
\newlabel{thm: al}{{3.2}{9}}
\newlabel{eq: risk1}{{10}{9}}
\newlabel{eq: risk2}{{11}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Imbalanced Data}{9}}
\@writefile{toc}{\contentsline {paragraph}{Imbalance Problem}{9}}
\newlabel{eq: mdf_nw}{{12}{9}}
\citation{gretton2009covariate}
\newlabel{eq: mmd1}{{14}{10}}
\newlabel{thm: corr1}{{3.3}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Unfairness Diagnostics: Worst-Case Violation}{10}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Certifying Fairness Algorithm (CFA) \relax }}{11}}
\newlabel{algo: 1}{{1}{11}}
\@writefile{toc}{\contentsline {paragraph}{Worst-Case Violation Problem}{11}}
\newlabel{eq: wvio}{{16}{11}}
\@writefile{toc}{\contentsline {paragraph}{Worst-Case Violation Algorithm (WVA)}{11}}
\newlabel{thm: algo3_ana}{{3.4}{11}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Worst Violation Algorithm (WVA)\relax }}{12}}
\newlabel{algo: 3}{{2}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}[\textbf  {name}]}{12}}
\@writefile{toc}{\contentsline {paragraph}{Architecture}{12}}
\@writefile{toc}{\contentsline {paragraph}{Cross-Validation}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Synthetic Data}{13}}
\@writefile{toc}{\contentsline {paragraph}{Sample Complexity}{13}}
\@writefile{toc}{\contentsline {paragraph}{Unbalanced Data}{13}}
\newlabel{fig: 1a}{{2a}{14}}
\newlabel{sub@fig: 1a}{{a}{14}}
\newlabel{fig: 1b}{{2b}{14}}
\newlabel{sub@fig: 1b}{{b}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Certifying $\gamma $- multi differential unfairness. The auditor is a decision tree whose depth is tuned using a $5$-fold cross validation. The weights function $u$ is obtained using a neural network with four hidden layers with eight neurons each. The plots show the average of $100$ experiments. Figure 2a\hbox {} auditor's bias when estimating $\gamma _{a}$ is measured by deviations from the $45\ensuremath  {^\circ }$ line; the unbalance parameter $\mu $ is set to $0$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; and, the intensity $\beta $ of the fairness violation varies from $0$ to $0.5$. Figure 2b\hbox {}: bias is measured as the difference $\gamma _{a}-\gamma _{o}$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; the intensity $\beta $ of the fairness violation is set to $0.5$; the balancing parameter $\mu $ varies from $-0.3$ to $0.3$. \relax }}{14}}
\@writefile{toc}{\contentsline {paragraph}{Concept Class}{14}}
\@writefile{toc}{\contentsline {paragraph}{Worst Violations}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Effect of auditor's class on auditor's performance.\relax }}{15}}
\newlabel{fig: 2a}{{3}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Certifying $\gamma $- multi differential unfairness. The auditor is a decision tree whose depth is tuned using a $5$-fold cross validation. The weights function $u$ is obtained using a neural network with four hidden layers with eight neurons each. The plots show the average of $100$ experiments. Figure 3\hbox {} auditor's bias when estimating $\gamma _{a}$ is measured by deviations from the $45\ensuremath  {^\circ }$ line; the unbalance parameter $\mu $ is set to $0.2$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; and, the intensity $\beta $ of the fairness violation varies from $0$ to $0.5$. \relax }}{15}}
\newlabel{fig: 3a}{{\caption@xref {fig: 3a}{ on input line 612}}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Finding $\delta $ for the worst violation of multi-differential fairness. The auditor is a RBF support vector machine whose regularization is tuned using a $5$-fold cross validation. The weights function $u$ is obtained using a neural network with four hidden layers with eight neurons each. The plots show the average of $100$ experiments. auditor's bias when estimating $\gamma _{a}$ is measured by deviations from the $45\ensuremath  {^\circ }$ line; the unbalance parameter $\mu $ is set to $0.2$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; and, the intensity $\beta $ of the fairness violation is set to $0.5$. The bias in the estimated $\delta $ is measured as the difference $\delta _{a}-\delta _{o}$ \relax }}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Case Study: COMPAS}{16}}
\@writefile{toc}{\contentsline {paragraph}{Data Description}{16}}
\@writefile{toc}{\contentsline {paragraph}{Certifying the Lack of Differential Fairness}{16}}
\newlabel{tab: 1}{{\caption@xref {tab: 1}{ on input line 636}}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Certifying the lack of differential fairness in COMPAS risk classification. Features are as follows: I: count of prior felonies; II: degree of current charge (criminal vs non-criminal); III: age; IV: count of juvenile prior felonies; V: count of juvenile prior misdemeanors. Standard deviations are obtained by drawing $100$ train/test splits. In the first column, Race, the protected attribute is a binary variable indicating whether an individual is self-identified as Afro-American; in the second column, Gender, the protected attribute is a binary variable indicating whether an individual is self-identified as Male\relax }}{16}}
\@writefile{toc}{\contentsline {paragraph}{Worst Violations}{16}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Identifying the worst-case violation of differential fairness in the COMPAS risk score. The protected attribute is whether the individual is self-identified as African American. The worst-case violation algorithm is run with a random forest of $100$ tree stumps of depth 2 and an incremental weight increase equal to $0.1$. The algorithm is run $100$ times, each time with a different $0.7/0.3$ train/test set split. Estimates in the tables are obtained from the test set. \relax }}{17}}
\newlabel{tab: 2}{{2}{17}}
\@writefile{toc}{\contentsline {paragraph}{Disparate Treatment}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Other Datasets: Group Fairness vs. Multi-Differential Fairness}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Analysis of Algorithm 2}{17}}
\newlabel{eq: opt1}{{19}{17}}
\newlabel{eq: bound}{{27}{18}}
\newlabel{eq: proof_bound}{{29}{18}}
\newlabel{eq: opt_bound}{{32}{19}}
\newlabel{thm1}{{5.1}{19}}
\bibstyle{plain}
\bibdata{references}
\bibcite{Ricci}{1}
\bibcite{atlantic2016}{2}
\bibcite{ProPublica2016}{3}
\bibcite{Loomis}{4}
\bibcite{NY2017}{5}
\bibcite{calsamiglia2009decentralizing}{6}
\bibcite{chouldechova2017fair}{7}
\bibcite{chouldechova2018frontiers}{8}
\bibcite{cortes2010learning}{9}
\bibcite{cortes2008sample}{10}
\bibcite{Loubes2018}{11}
\bibcite{dwork2012fairness}{12}
\bibcite{dwork2014algorithmic}{13}
\bibcite{feldman2015certifying}{14}
\bibcite{feldman2012agnostic}{15}
\bibcite{freedman2008weighting}{16}
\bibcite{gretton2009covariate}{17}
\bibcite{hebert2017calibration}{18}
\bibcite{jagielski2018differentially}{19}
\bibcite{kearns2017preventing}{20}
\bibcite{kearns1994toward}{21}
\bibcite{kim2018fairness}{22}
\bibcite{rosenbaum1983central}{23}
