\relax 
\citation{calsamiglia2009decentralizing}
\citation{calsamiglia2009decentralizing}
\citation{NY2017}
\citation{atlantic2016}
\citation{ProPublica2016}
\citation{ProPublica2016}
\citation{Ricci}
\citation{Loomis}
\citation{Loomis}
\citation{dwork2014algorithmic}
\citation{feldman2015certifying}
\citation{dwork2012fairness}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{kim2018fairness}
\citation{hebert2017calibration}
\citation{kearns2017preventing}
\citation{ustun2018actionable}
\citation{russell2019efficient}
\citation{chouldechova2018frontiers}
\citation{hebert2017calibration}
\citation{kim2018fairness}
\citation{kearns2017preventing}
\citation{kearns2017preventing}
\citation{dwork2012fairness}
\citation{hebert2017calibration}
\citation{kim2018fairness}
\citation{kearns2017preventing}
\citation{hebert2017calibration}
\citation{kim2018fairness}
\citation{dwork2014algorithmic}
\citation{feldman2015certifying}
\citation{Loubes2018}
\citation{feldman2015certifying}
\@writefile{toc}{\contentsline {paragraph}{Related Work}{2}}
\@writefile{toc}{\contentsline {paragraph}{Contributions}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Individual and Multi-Differential Fairness}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Preliminary}{3}}
\@writefile{toc}{\contentsline {paragraph}{Notations}{3}}
\citation{dwork2014algorithmic}
\citation{jagielski2018differentially}
\citation{foulds2018intersectional}
\citation{dwork2012fairness}
\citation{chouldechova2018frontiers}
\@writefile{toc}{\contentsline {paragraph}{Assumptions}{4}}
\newlabel{ass: 1}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Individual Differential Fairness}{4}}
\@writefile{toc}{\contentsline {paragraph}{Individual Differential Fairness}{4}}
\newlabel{def: idf}{{2.1}{4}}
\newlabel{eq: idf}{{1}{4}}
\@writefile{toc}{\contentsline {paragraph}{Differential Fairness and Distance of Distributions}{4}}
\newlabel{eq: maxdiv_idf}{{3}{4}}
\@writefile{toc}{\contentsline {paragraph}{Relation with Differential Privacy}{4}}
\citation{Ricci}
\citation{Loomis}
\citation{feldman2015certifying}
\citation{chouldechova2017fair}
\@writefile{toc}{\contentsline {paragraph}{Individual Fairness}{5}}
\@writefile{toc}{\contentsline {paragraph}{Intention in Disparate Treatment}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Multi-differential fairness}{5}}
\newlabel{def: mdf}{{2.2}{5}}
\newlabel{eq: mdf}{{4}{5}}
\@writefile{toc}{\contentsline {paragraph}{Disparate Treatment versus Disparate Impact}{5}}
\citation{kim2018fairness}
\citation{kearns2017preventing}
\citation{hebert2017calibration}
\@writefile{toc}{\contentsline {paragraph}{Collection of Indicators.}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Fairness Diagnostics}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Certifying (the Lack) Fairness and Agnostic Learning}{6}}
\@writefile{toc}{\contentsline {paragraph}{Multi Differential Fairness and Balanced Distribution}{6}}
\newlabel{eq: mdf_w}{{6}{7}}
\newlabel{eq: mdf_viol1}{{7}{7}}
\newlabel{eq: unfair}{{8}{7}}
\newlabel{lem: 1}{{3.1}{7}}
\citation{feldman2012agnostic}
\citation{kearns1994toward}
\citation{cortes2010learning}
\citation{rosenbaum1983central}
\citation{freedman2008weighting}
\citation{cortes2010learning}
\citation{gretton2009covariate}
\citation{cortes2008sample}
\newlabel{thm: al}{{3.2}{8}}
\newlabel{eq: risk1}{{9}{8}}
\newlabel{eq: risk2}{{10}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Imbalanced Data}{8}}
\@writefile{toc}{\contentsline {paragraph}{Imbalance Problem}{8}}
\newlabel{eq: mdf_nw}{{11}{8}}
\citation{gretton2009covariate}
\newlabel{eq: mmd1}{{13}{9}}
\newlabel{thm: corr1}{{3.3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Unfairness Diagnostics: Worst-Case Violation}{9}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Certifying Fairness Algorithm (CFA) \relax }}{10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{algo: 1}{{1}{10}}
\@writefile{toc}{\contentsline {paragraph}{Worst-Case Violation Problem}{10}}
\newlabel{eq: wvio}{{15}{10}}
\@writefile{toc}{\contentsline {paragraph}{Worst-Case Violation Algorithm (WVA)}{10}}
\newlabel{thm: algo3_ana}{{3.4}{10}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Worst Violation Algorithm (WVA)\relax }}{11}}
\newlabel{algo: 3}{{2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Unfairness Diagnostic: Individual Recourse}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Synthetic Data}{11}}
\@writefile{toc}{\contentsline {paragraph}{Sample Complexity}{12}}
\newlabel{fig: 1a}{{1a}{12}}
\newlabel{sub@fig: 1a}{{a}{12}}
\newlabel{fig: 1b}{{1b}{12}}
\newlabel{sub@fig: 1b}{{b}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Certifying $\gamma $- multi differential unfairness. The auditor is a decision tree whose depth is tuned using a $5$-fold cross validation. The weights function $u$ is obtained using a neural network with four hidden layers with eight neurons each. The plots show the average of $100$ experiments. Figure 1a\hbox {} auditor's bias when estimating $\gamma _{a}$ is measured by deviations from the $45\ensuremath  {^\circ }$ line; the unbalance parameter $\mu $ is set to $0$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; and, the intensity $\beta $ of the fairness violation varies from $0$ to $0.5$. Figure 1b\hbox {}: bias is measured as the difference $\gamma _{a}-\gamma _{o}$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; the intensity $\beta $ of the fairness violation is set to $0.5$; the balancing parameter $\mu $ varies from $-0.3$ to $0.3$. \relax }}{12}}
\@writefile{toc}{\contentsline {paragraph}{Unbalanced Data}{13}}
\@writefile{toc}{\contentsline {paragraph}{Concept Class}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Effect of auditor's class on auditor's performance.\relax }}{13}}
\newlabel{fig: 2a}{{2}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Certifying $\gamma $- multi differential unfairness. The auditor is a decision tree whose depth is tuned using a $5$-fold cross validation. The weights function $u$ is obtained using a neural network with four hidden layers with eight neurons each. The plots show the average of $100$ experiments. Figure 2\hbox {} auditor's bias when estimating $\gamma _{a}$ is measured by deviations from the $45\ensuremath  {^\circ }$ line; the unbalance parameter $\mu $ is set to $0.2$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; and, the intensity $\beta $ of the fairness violation varies from $0$ to $0.5$. \relax }}{13}}
\@writefile{toc}{\contentsline {paragraph}{Worst Violations}{13}}
\newlabel{fig: 3a}{{\caption@xref {fig: 3a}{ on input line 539}}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Finding $\delta $ for the worst violation of multi-differential fairness. The auditor is a RBF support vector machine whose regularization is tuned using a $5$-fold cross validation. The weights function $u$ is obtained using a neural network with four hidden layers with eight neurons each. The plots show the average of $100$ experiments. auditor's bias when estimating $\gamma _{a}$ is measured by deviations from the $45\ensuremath  {^\circ }$ line; the unbalance parameter $\mu $ is set to $0.2$; the size $\alpha $ of sub-population with a fairness violation is set to $0.1$; and, the intensity $\beta $ of the fairness violation is set to $0.5$. The bias in the estimated $\delta $ is measured as the difference $\delta _{a}-\delta _{o}$ \relax }}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Case Study: COMPAS}{14}}
\@writefile{toc}{\contentsline {paragraph}{Data Description}{14}}
\@writefile{toc}{\contentsline {paragraph}{Certifying the Lack of Differential Fairness}{14}}
\newlabel{tab: 1}{{\caption@xref {tab: 1}{ on input line 563}}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Certifying the lack of differential fairness in COMPAS risk classification. Features are as follows: I: count of prior felonies; II: degree of current charge (criminal vs non-criminal); III: age; IV: count of juvenile prior felonies; V: count of juvenile prior misdemeanors. Standard deviations are obtained by drawing $100$ train/test splits. In the first column, Race, the protected attribute is a binary variable indicating whether an individual is self-identified as Afro-American; in the second column, Gender, the protected attribute is a binary variable indicating whether an individual is self-identified as Male\relax }}{15}}
\@writefile{toc}{\contentsline {paragraph}{Worst Violations}{15}}
\@writefile{toc}{\contentsline {paragraph}{Disparate Treatment}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Identifying the worst-case violation of differential fairness in the COMPAS risk score. The protected attribute is whether the individual is self-identified as African American. The worst-case violation algorithm is run with a random forest of $100$ tree stumps of depth 2 and an incremental weight increase equal to $0.1$. The algorithm is run $100$ times, each time with a different $0.7/0.3$ train/test set split. Estimates in the tables are obtained from the test set. \relax }}{16}}
\newlabel{tab: 2}{{2}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Other Datasets: Group Fairness vs. Multi-Differential Fairness}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Analysis of Algorithm 2}{16}}
\newlabel{eq: opt1}{{19}{16}}
\newlabel{eq: bound}{{27}{17}}
\newlabel{eq: proof_bound}{{29}{17}}
\newlabel{eq: opt_bound}{{32}{18}}
\newlabel{thm1}{{5.1}{18}}
\bibstyle{plain}
\bibdata{references}
\bibcite{Ricci}{1}
\bibcite{atlantic2016}{2}
\bibcite{ProPublica2016}{3}
\bibcite{Loomis}{4}
\bibcite{NY2017}{5}
\bibcite{calsamiglia2009decentralizing}{6}
\bibcite{chouldechova2017fair}{7}
\bibcite{chouldechova2018frontiers}{8}
\bibcite{cortes2010learning}{9}
\bibcite{Loubes2018}{10}
\bibcite{dwork2012fairness}{11}
\bibcite{dwork2014algorithmic}{12}
\bibcite{feldman2015certifying}{13}
\bibcite{feldman2012agnostic}{14}
\bibcite{freedman2008weighting}{15}
\bibcite{gretton2009covariate}{16}
\bibcite{hebert2017calibration}{17}
\bibcite{jagielski2018differentially}{18}
\bibcite{kearns2017preventing}{19}
\bibcite{kearns1994toward}{20}
\bibcite{kim2018fairness}{21}
\bibcite{rosenbaum1983central}{22}
\bibcite{russell2019efficient}{23}
\bibcite{ustun2018actionable}{24}
