\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{pgfplots}

\usepackage{subcaption}
\usepackage{gensymb}
\usepackage{amsmath,amsfonts,amssymb,amsthm,epsfig,epstopdf,titling,url,array}
\usepackage{enumerate}
\usepackage[a4paper, total={6in, 8in}]{geometry}

\newtheorem{thm}{Theorem}[section]
\newtheorem*{thmt*}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\pgfplotsset{compat=1.15}

\newtheorem{defn}{Definition}[section]
\title{Auditing For Fairness in Machine Learning}
\author{}
\date{November 2018}

\begin{document}
\maketitle

\section{Metric-Free Individual Fairness}
\subsection{Preliminaries}

\paragraph{Audited Classifier}
The objective of this paper is to audit a classifier $f:\mathfrak{X}^{*} \rightarrow \{0,1\}$, where $\mathfrak{X}^{*}$ is a $d$-dimensional feature space. The Feature space is the Cartesian product of auditing features $\mathfrak{X}$, non-auditing features $\mathfrak{X}^{'}$ and protected attributes $\mathfrak{A}$: $\mathfrak{X}^{*} = \mathfrak{X} \times \mathfrak{X}^{'} \times \mathfrak{A}$.  The data is labeled by $y\in \{0, 1\}$ and the classifier $f$ is trained to label the data $\mathfrak{X}^{*}\times \{0, 1\}$. 

\bigskip
Not all features in $\mathfrak{X}^{*}$ are to be used to audit the classifier $f$. The auditor decides on features in $\mathfrak{X}$ along which individuals are considered similar and on features $\mathfrak{X}^{'}$ which should not be considered when  comparing two individuals.  Given the objective to guarantee similar treatment regardless of protected attribute, protected attributes are not auditing features. But the exclusion could extend to other features of $\mathfrak{X}^{*}$ depending on the auditor's definition of similarity. For example, if $f$ classify loan according to their probability of repayment, the auditor may consider that credit score should be used to define individual similarity, but that zipcode, because correlated with races, should not be an auditing feature, although it was used to learn $f$.  Defining the auditing features empowers the decision maker to choose along which dimensions she wants individuals to be treated the same.

\paragraph{Label Access.}
The auditor takes random draws of individual $x^{*}=(x, x^{'}, a)\in \mathfrak{X} \times \mathfrak{X}^{'} \times \mathfrak{A} $ from a distribution $\mathfrak{D}$ over $\mathfrak{X}^{*}$. For any draw $x^{*}\sim \mathfrak{D}$,  the auditor can apply a reassignment of protected attributes $\pi: \mathfrak{A} \rightarrow \mathfrak{A}$ that transforms $x^{*}= (x, x^{'}, a)$ into $x^{*}_{\pi}=(x, x^{'}, \pi(a))$. For example, if $\mathfrak{A}=\{0,1\}$, then the auditor can apply three non-trivial reassignments: $(\pi(0)=1, \pi(1)=1)$, $(\pi(0)=0, \pi(1)=0)$ and $(\pi(0)=1, \pi(1)=0)$. We assume that given a $x^{*}\sim \mathfrak{D}$, the auditor obtains $f(x^{*}_{\pi})$ for any reassignment $\pi$ of protected attributes. This is equivalent to a $1Q$-membership query as in \cite{awasthi2013learning}. In addition to querying an oracle $EX(f, D)$, for any sample  example $x^{*}$, the auditor can obtain $f(x^{*}_{\pi})$ from membership query $MEM(f)$ where $x_{\pi}^{*}$ differs from $x^{*}$  by a Hamming distance of one.  


\paragraph{Collection of Indicators.}
An indicator is a subset $G$ of $\mathfrak{X}^{*}$ and defines a function $g: \mathfrak{X}^{*} \rightarrow \{0, 1\}$ such that $g(x)=1$ if and only if $x\in G$. $\mathbb{C}$ denotes the collection $\mathbb{C}$ of indicators $G$. Think of $\mathbb{C}$ as the collection of all groups of individuals for which this paper's notion of fairness treatment will be applied to. 

 

\subsection{Metric-Free Individual Fairness.}

\paragraph{Metric-Based Individual Fairness.}
So far, definition of individual fairness in the literature have relied on a similarity metric to impose that similar individuals are treated similarly. With this paper's notations, individual fairness in \cite{dwork2012fairness} is defined as follows:


\begin{defn}(Individual fairness (from \cite{dwork2012fairness}))
\label{def: if}
Let $\delta:\mathfrak{X}^{*} \times \mathfrak{X}^{*} \rightarrow \mathbb{R}$ be a similarity metric. A classifier $f$ is $\delta$-individually fair if for all $x_{1}^{*}, x_{2}^{*} \in \mathfrak{X}^{*}$, 
$$|f(x_{1}^{*}) - f(x_{2}^{*})| \leq \delta(x_{1}^{*}, x_{2}^{*}).$$
\end{defn}

Observe, that given its purpose, the similarity metric should only be defined on the space $\mathfrak{X} \times \mathfrak{X}$.For example, in the loan repayment example, the metric will not measure any distance between similar individuals living in different zipcodes. 

\paragraph{Metric-Free Individual Fairness.}
This paper redefines the concept of individual fairness as \textit{individuals with similar features but their protected attributes should be treated the same}. 


\begin{defn}(Metric-free individual fairness)
\label{def: mfif}
Consider a $\alpha$-large collection $\mathbb{C}_{\alpha}$ of indicators on $\mathfrak{X}^{*}$. For $0\leq \beta <1$, a classifier $f$ is $(\mathbb{C}_{\alpha}, \beta)$-metric free individual fair with respect to $\mathfrak{A}$ if for all reassignments $\pi: \mathfrak{A} \rightarrow \mathfrak{A}$ and for all $G\in \mathbb{C}_{\alpha}$ with :
$$  E_{x^{*}\sim G}[|f(x^{*}) - f(x^{*}_{\pi})|] \leq \beta.$$
\end{defn}

Metric-free individual fairness formalizes the idea of fairness defined in \cite{calsamiglia2009decentralizing} and borrowed in \cite{dwork2012fairness}: \textit{"In a global justice problem, equality of opportunity is satisfied if individual well-being is 
independent of exogenous irrelevant characteristics"}. The degree of independence to \textit{irrelevant characteristics} is controlled by the value of $\beta$: smaller values of $\beta$ guarantees a stronger level of fairness. 

\bigskip
The most noticeable difference between this paper's metric-free definition of individual fairness and previous definitions is that the fairness guarantee is free of similarity metric. The reason is that metric-free fairness guarantees similar treatment across individuals who are exactly similar but along protected attributes. A metric-free definition of individual fairness comes at the cost of no guarantee of similar treatment within protected groups.

\bigskip
 Lastly, metric-free individual fairness is a multiple-individuals level notion of fairness. It protects any group of individuals $G\in \mathbb{C}_{\alpha}$. The collection of indicators $\mathbb{C}_{\alpha}$ is as in \cite{kim2018fairness} the computational bound on the granularity of metric-free individual fairness. As argued in \cite{kim2018fairness}, this relaxation is necessary to audit for fairness in polynomial time. For example, if $\mathbb{C}_{\alpha}$ is represented by polynomial-sized circuits, the definition of metric-free fairness guarantees fairness within the bound of any indicator that can be computed with polynomial-sized circuits.
 
 
 \subsection{Relation to Differential Fairness}
 To understand the fairness guarantee offer by  metric-free individual fairness, this section relates metric-free individual fairness to a notion of differential individual fairness. Differential individual fairness is a granular extension of the differential fairness as defined by \cite{Foulds2018}. Consider a collection of indicators $\mathbb{C}_{\alpha}$. For any $G\in \mathbb{C}_{\alpha}$, define an adjacent set $G_{\pi}$ that is made of all elements of $G$ for which all protected attributes have been reassigned according to $\pi$: $G_{\pi}=\{(x, x^{'}, \pi(a)| (x, x^{'}, a) \in G\}$. Differential individual fairness imposes that reassigning protected attributes does not change substantially the 
 level dissimilarity in each group of individuals in $\mathbb{C}$. Formally, 
 
 \begin{defn} (Differential Individual Fairness)
 \label{def: dif}
 $f$ is $(\mathbb{C}_{\alpha}, \tau)$- differential individually fair if and only if for any reassignment $\pi: \mathfrak{A} \rightarrow \mathfrak{A}$ and for any $G \in \mathbb{C}$,
 
 $$  E_{(x^{*}_{1}, x_{2}^{*})\sim G\times G}\left[\left|f(x_{\pi1}^{*}) - f(x_{\pi2}^{*})\right|\right] \leq E_{(x^{*}_{1}, x_{2}^{*})\sim G\times G}\left[\left|f(x_{1}^{*}) - f(x_{2}^{*})\right|\right] + \tau $$
 \end{defn}
 
 
 \begin{thm}
 \label{thm: dif}
 Consider a $\alpha$-large collection $\mathbb{C}_{\alpha}$ of indicators on $\mathfrak{X}^{*}$. Suppose that $f$ is $(\mathbb{C}_{\alpha}, \beta)$-metric free individual fair with respect to $\mathfrak{A}$. Then, $f$ is $(C_{\alpha}, 2\beta)$-differential individually fair.
 \end{thm}
 
 A classifier could violate similarity constraints as in \ref{def: if} within each protected groups. Theorem \ref{thm: dif} implies that if $f$ is $(\mathbb{C}_{\alpha}, \beta)$-metric free individually fair, the degree of violations of the Lipchitz conditions in \ref{def: if} is not increased by more than $2\beta$ when reassigning protected attributes with subgroups in $\mathbb{C}_{\alpha}$. The idea of differentiality is borrowed from the differential privacy work of :  metric-free individual fairness guarantees that the degree of dissimilarity within each group of $\mathbb{C}_{\alpha}$ does not reveal anything about the distribution of protected attributes within that group. 

\subsection{Relation to Statistical Parity and Equalized Odds}

\paragraph{Relation with Statistical Measures of Fairness.}
The concept of metric-free individual fairness bridges both concepts of statistical fairness and individual fairness.  Informally, smaller values of $\alpha$ provides a more granular definition of fairness; larger values of alpha corresponds more to a group/statistical level definition. 

\bigskip
Formally, the next results shows that the definition \ref{def: mfif} encompasses two prevalent notions of statistical fairness:statistical parity, $SP$, and equalized odds, $EO$ (see \cite{hardt2016equality}):

\begin{thm}(From metric-free fairness to SP and EO)
\label{thm: SP}
Consider a classifier $f: \mathbb{X} \rightarrow \{0, 1\}$.  If $f$ is $(\alpha,\beta)$-metric individually fair with $\alpha \leq \min_{a\in \mathbb{A}}\{Pr[f=1 \& A=a]$, then 
\begin{enumerate}[(a)]
    \item $f$ satisfies $\alpha(1-\beta)$-statistical parity, i.e for all $a, a^{'}\neq a \in \mathbb{A}$
$$ |Pr[f=1, A=a] - Pr[f=1, A=a^{'}]| \leq \alpha(1-\beta)$$
    \item $f$ satisfies $\alpha(1-\beta)$-equalized odds, i.e for all $a, a^{'}\neq a \in \mathbb{A}$ and $y\in\{0,1\}$
$$ |Pr[f=1, A=a, Y=y] - Pr[f=1, A=a^{'}, Y=y]| \leq \alpha(1-\beta)$$
\end{enumerate}
\end{thm}

When $\alpha \rightarrow 0$ and/or $\beta\rightarrow 1$, the definition of metric-free individual fairness implies notion of  exact statistical parity or equalized odds (see \cite{hardt2016equality}).

\paragraph{Relation with Metric-Based Measure of Individual Fairness.}
The main novelty of the concept of metric-free individual fairness is that it does not require defining a metric in the audit space as in \cite{dwork2012fairness} or sampling from a metric as in \cite{kim2018fairness}. Although it is a weaker notion of individual fairness, it guarantees the type of protection intended by stronger definition of individuals fairness. \cite{dwork2012fairness} provide three motivations to use of individual fairness over aggregate concepts: subset targeting,  self-fulfilling prophecy and reduced utility. Subset targeting occurs, for example, when an advertisement company delivers ads related to mortgage refinancing in the same proportions across demographic groups, but target homeowners... need some context to show that metric-free individual fairness covers situations that motivate individual fairness in the first place.  Then formal statement of what is covered by metric-free fairness.

\begin{thm}
\label{thm: df}
$f$ is a $(\mathbb{C}, \beta)$-metric free individually fair classifier if and only if $f$ is $(\mathbb{C}, \beta)$- differentially fair.
\end{thm}


\begin{thm}
\label{thm: mf}
Suppose that $f$ is $(\mathbb{C}, \beta)$-metric free individually fair classifier. Let $\delta$ be a metric on $\mathbb{X}\times \mathbb{X}$. Define $\mathfrak{C}(\mathbb{C})$ the collection of comparisons induced by $\mathbb{C}$ as $\mathfrak{C}(\mathbb{C})= \{c: \mathbb{X}\times \mathbb{X} \rightarrow \{0, 1\}| \exists g\in \mathbb{C} \mbox{ s.t. } c(x, x^{'})=g(x)g(x^{'})\}$. Then, $f$ is $(\mathfrak{C}(\mathbb{C}), \tau + \beta, \delta)$ multiple fair if and only if  
\end{thm}


does not require a metric in the audit space $\mathbb{Z}$, because similarity between individuals is measured between individuals with the same auditing features $z$ but different protected attributes. This is different from the definition of individual fairness in \cite{dwork2012fairness} that measures individuals across all individuals, but requires to define a similarity metric. The following definition of individual fairness is borrowed from \cite{dwork2012fairness}:



On one hand, metric-free individual fairness is weaker than individual fairness since it only protects group of individuals of size $\alpha$ and since its protection is only partial (unless $\beta \rightarrow 1$). On the other hand, metric-free individual fairness proposes a notion of fairness that is true regardless on how individual similarity is measured. 

\bigskip
Example where metric-free individual fairness is the right concept: 


\section{Auditing with Membership Queries}

\paragraph{$\gamma$- metric free individual unfairness}
Violation of metric-free fairness can be written as follows:

\begin{defn}
\label{def: unfair}
A classifier $f$ is $\gamma$-metric free individually unfair if and only if there exists an indicator $g\in \mathbb{C}$  and an assignment $\pi:\mathfrak{A} \rightarrow \mathfrak{A}$ such that
$$\langle g, u_{\pi}\rangle \geq \gamma,$$
where $u_{\pi}(x)=2*|f(x^{*})-f(x_{\pi}^{*})| - 1$. Then, $g$ is a $\gamma$-unfairness certificate. 
\end{defn}
The definition \ref{def: unfair} is equivalent to a violation of metric-free individually fairness in \ref{def: mfif} with $\gamma=\alpha (1-\beta)$ since 

$$ \langle g, u_{\pi} \rangle= E[g(x^{*})u_{\pi}(x^{*})] = 2Pr[g(x^{*})=1]E[u_{\pi}(x)|g(x)=1] - \rho$$.

$1-\beta=\frac{\rho + \gamma}{4\alpha^{'}}+ \frac{1}{2}$
\paragraph{Auditing}

\begin{defn}
Consider the class of indicators $\mathbb{C}$, a hypothesis class $\mathbb{H}$ and $\gamma^{'} < \gamma$. A $(\mathbb{C}, \mathbb{H}, \gamma, \gamma^{'})$-auditing algorithm with respect to distribution $\mathfrak{D}$ is an algorithm $\mathfrak{M}$ that for any classifier $f$, any distribution $D\in \mathfrak{D}$, when given oracle access to $f$, 
\begin{enumerate}
    \item With probability $1-\delta$, provides a $(\mathbb{H}, \gamma^{'})$- unfairness certificate if $f$ is $(\mathbb{C}, \gamma)$-metric free individually unfair.
    \item With probability $1$, returns "fair" if $f$ is $(\mathbb{C}, \gamma)-$ metric free individually fair.
    \item Runs in $poly(\frac{1}{\delta})$ including queries to $EX(f, D)$ and membership queries $MQ(f)$.
\end{enumerate} 
\end{defn}

\paragraph{Agnostic Learning}
\begin{defn}
A concept class $\mathbb{C}$ is agnostically efficiently learnable under distribution $\mathfrak{D}$ if and only if there exists an algorithm $\mathfrak{M}$ that for all $\epsilon, \delta >0$ in $poly(\frac{1}{\delta}, \epsilon)$ outputs with probability $1-\delta$ a function $h\in \mathbb{C}$ such that
$$ <f,h> \geq max_{g\in \mathbb{C}}<f, g> + \epsilon. $$
\end{defn}

 
\section{Experimental Results}
\subsection{Synthetic Data}

\paragraph{With Oracle Access to Audited Classifier}
The first set of experiments illustrates how the auditing algorithm in section delivers the correct unfairness certificates when oracle access to the audited classifier $f$ is allowed. Figure \ref{fig: 1a} shows that when the auditing space $\mathbb{Z}$ is the same as the training features $\mathbb{X}$ used to learn $f$, the auditing algorithm delivers a $\gamma$-unfairness certificate where $\gamma$ is exactly equal to the fraction of individuals treated unfairly in the sample. Figure \ref{fig: 1b} shows that the auditing algorithm is robust to using only a subset of the training features, $\mathbb{Z} \neq \mathbb{X}$. Suppose for example that values for $X_{2}$ are zipcodes and that the auditor considers that individuals with similar values of $X_{1}$ but different zipcodes should be treated similarly. 

\begin{figure}
\begin{subfigure} {.55\linewidth}
\begin{tikzpicture}
\begin{axis}[
    xlabel={$\nu$},
    ylabel={$\gamma$},
    xmin=0, xmax=1.0,
    ymin=0, ymax=1.0,
    xtick={0, 0.2, 0.4, 0.6, 0.8, 1.0},
    ytick={0, 0.2, 0.4, 0.6, 0.8, 1.0},
    legend pos=north west,
    ymajorgrids=true,
    grid style=dashed,
]
 
\addplot[
    color=blue,
    mark=square,
    ]
    table[x=gamma, y=unfairness_all, col sep=comma]{../results/synth_oracle_exp1.csv};
\end{axis}
\end{tikzpicture}
\caption{Auditing features are $X_{1}$ and $X_{2}$.}
\label{fig: 1a}
\end{subfigure}
\begin{subfigure} {.55\linewidth}
\begin{tikzpicture}

\begin{axis}[
    xlabel={$\nu$},
    xmin=0, xmax=1.0,
    ymin=0, ymax=1.0,
    xtick={0, 0.2, 0.4, 0.6, 0.8, 1.0},
    ytick={0, 0.2, 0.4, 0.6, 0.8, 1.0},
    legend pos=north west,
    ymajorgrids=true,
    grid style=dashed,
]
 
\addplot[
    color=blue,
    mark=square,
    ]
    table[x=gamma, y=unfairness_x1, col sep=comma]{../results/synth_oracle_exp1.csv};
    
\end{axis}
\end{tikzpicture}
\caption{Auditing features are $X_{1}$.}
\label{fig: 1b}
\end{subfigure}
\caption{Metric-free individual unfairness versus fraction of individuals unfairly treated.}
\end{figure}

\paragraph{Metric-free Individual Fairness versus Other Fairness Measures.}
The first set of experiments illustrates how the concept of metric-free individual fairness relates to other existing definitions of fairness. Figures \ref{fig: 1a} and \ref{fig: 1b} plots measures statistical parity and  difference in true positive rates across protected groups $A=\{0, 1\}$ for different levels of metric-free individual fairness. Figure \ref{fig: 1a} shows that the level of statistical parity between protected groups -- $SP(\nu)=|Pr[f=1, A=0] - Pr[f=1, A=1]|$ -- is bounded below by $\nu$, which equals $\alpha(1-\beta)$ in theorem \ref{thm: SP} and measures the unfairness of classifier $f$ once the data has been modified. Figure \ref{fig: 1b} illustrates theorem \ref{thm: SP} for equalized odds: metric-free individual fairness implies that true positive rates -- $EO(\nu)= |Pr[f=1|A=1, Y=1] - Pr[f=1|A=0, Y=1]|$ -- cannot differ by more than $\nu$ across groups $A=0$ and $A=1$. Similar results could be obtained for true negative rates.

\bigskip
Figure compares the degree $\nu$ of metric-free individual unfairness to the fraction of individual pairs $(z, a)$ and $(z^{'}, a^{'})$ that are treated differently by the classifier $f$. Theorem indicates that the probability of fair treatment in the sense of \cite{dwork2012fairness} should be bounded below by the probability of fair treatment in the sense of this paper. 

\begin{figure}
\begin{subfigure} {.5\linewidth}
\begin{tikzpicture}
\begin{axis}[
    xlabel={$\nu$},
    ylabel={$SP(\nu)$},
    xmin=0, xmax=0.5,
    ymin=0, ymax=0.5,
    xtick={0,0.1,0.2,0.3,0.4,0.5},
    ytick={0, 0.1, 0.2, 0.3, 0.4, 0.5},
    legend pos=north west,
    ymajorgrids=true,
    grid style=dashed,
]
 
\addplot[
    color=blue,
    mark=square,
    ]
    table[x=gamma, y=sp, col sep=comma]{../results/synth_exp_aggregate.csv};
\end{axis}
\end{tikzpicture}
\caption{Statistical parity}
\label{fig: 1a}
\end{subfigure}
\begin{subfigure} {.5\linewidth}
\begin{tikzpicture}

\begin{axis}[
    xlabel={$\nu$},
    ylabel={$EO(\nu)$},
    xmin=0, xmax=0.5,
    ymin=0, ymax=0.5,
    xtick={0,0.1,0.2,0.3,0.4,0.5},
    ytick={0, 0.1, 0.2, 0.3, 0.4, 0.5},
    legend pos=north west,
    ymajorgrids=true,
    grid style=dashed,
]
 
\addplot[
    color=blue,
    mark=square,
    ]
    table[x=gamma, y=tpr, col sep=comma]{../results/synth_exp_aggregate.csv};

    
\end{axis}
\end{tikzpicture}
\caption{True Positive Rates}
\label{fig: 1b}
\end{subfigure}

\end{figure}

\paragraph{Overlapping Distributions.}
The first set of experiments (figure to figure ) tests the theoretical results in theorem ... Figure plots the value of the individual fairness measure $\Delta$ against the fraction of unfair records $\nu$, when $f$ is a logistic classifier. As stated in theorem, $\Delta$ is equal to $\nu$ and thus, the plot aligns along the $45\degree$ line. 

changing the standard deviation $\sigma$ of the noise $\epsilon$. Figure \ref{fig: 1a} plots the value of $\Delta$ as a function of $\nu$ for value of $\sigma\in \{0, 0.1, 0.5, 1\}$ when $f$ is logistic regression and $\Delta$ is obtained by training a logistic classifier using auditing features $X_{1}, X_{2}$ and labels $\tilde{R_{f}},$ where  $\tilde{R_{f}}=R_{f}$ if $a=0$ and  $\tilde{R_{f}}=1 -R_{f}$ if $a=0$. The line $\Delta=\nu$ is consistent with theoretical results derived in the previous sections. Moreover, the variance of the noise in $Y^{*}$ and thus, the accuracy of the classifier $f$ do not affect the experimental results.

\section{Appendix}

\subsection{Proof of Theorem \ref{thm: SP}}
\begin{proof}
we show the results for statistical parity. The proof is similar for equalized odds. S
uppose that $f$ is $(\alpha,\beta)$-metric free individually fair with $\alpha \leq \min_{a\in \mathbb{A}}\{Pr[f=1 \& A=a]$. Let $p_{a}$ denote the probability than $f(z, a)\neq f(z, a^{'})$ conditional on  $f(z,a)=1$. We first argue that $p_{a} \leq \alpha(1-\beta)$. To do so, construct a set $G=\{z\in \mathbb{Z}| f(z,a)= 1 \& \; f(z,a^{'})=0\}$. Consider a subset $G^{'}$ of $G^{c}$ such that $Pr[z\in G^{'}]=\nu-\epsilon$ for some $\epsilon>0$. We choose $\nu$ such that $$\frac{p_{a}}{p_{a} + \nu -\epsilon} = 1-\beta, $$
or

\begin{equation}
\label{eq: nu}
\nu = \epsilon + \frac{\beta}{1-\beta}p_{a}.    
\end{equation}

Therefore, $Pr[z\in G^{'}\cup G]=p_{a} + \nu - \epsilon$. By definition of $(\alpha, \beta)$-metric free individual fairness, since $ \frac{p_{a}}{p_{a} + \nu -\epsilon} = 1-\beta$, $p_{a} + \nu -\epsilon < \alpha$. Therefore, by equation \eqref{eq: nu},

$$  p_{a} < (\alpha - \epsilon)(1-\beta).$$ Taking the limit $\epsilon \rightarrow 0$ leads to $p_{a}\geq \alpha(1-\beta)$. The same result holds for $p_{a^{'}}\equiv Pr[f(z, a^{'})=1 \& \; f(z,a)=0]$. Moreover,
\begin{equation}
    \begin{split}
        Pr[f(z, a)=1] - Pr[f(z, a^{'})=1] & =  Pr[f(z, a)=1 \& f(z, a^{'})=0] - Pr[f(z, a)=0 \& f(z, a^{'})=1] \\
         & = p_{a} - p_{a^{'}}
    \end{split}
\end{equation}
Therefore, 

$$|Pr[f(z, a)=1] - Pr[f(z, a^{'})=1]| \leq \alpha(1-\beta). $$
\end{proof}

\subsection{Proof of theorem \ref{thm: dif}}
Suppose that $f$ is a $(\mathbb{C}_{\alpha}, \beta)$-metric free individually fair classifier. Let $\pi: \mathbb{A} \rightarrow \mathbb{A}$ be a reassignment of protected attributes.

\begin{equation}
\begin{split}
    E_{(x^{*}_{1}, x^{*}_{2})\sim G \times G}\left[\left|f(x_{\pi1}^{*}) - f(x_{\pi2}^{*})\right|\right]  & = E_{(x^{*}_{1}, x^{*}_{2})\sim G \times G}\left[\left|f(x_{\pi1}^{*}) - f(x_{1}^{*}) + f(x_{1}^{*}) - f(x_{2}^{*}))\right.\right. \\
    & + \left.\left. f(x^{*}_{2}) - f(x_{\pi2}^{*})\right|\right] \\
    & \leq 2\beta + E_{(x^{*}_{1}, x^{*}_{2})\sim G \times G}\left[\left|f(x_{1}^{*}) - f(x_{2}^{*})\right|\right] 
    \end{split}
\end{equation}
by using a triangular inequality and then the definition of metric-free individual fairness. A similar argument can be written to show that  
\begin{equation}
    E_{(x^{*}_{1}, x^{*}_{2})\sim G \times G}\left[\left|f(x_{1}^{*}) - f(x_{2}^{*})\right|\right] \leq 2\beta +  E_{(x^{*}_{1}, x^{*}_{2})\sim G \times G}\left[\left|f(x_{\pi1}^{*}) - f(x_{\pi2}^{*})\right|\right]
\end{equation}

Therefore $f$ is $(\mathbb{C}_{\alpha}, 2\beta)$-differentially individually fair.

\bigskip
Conversely, suppose that $f$ is $(\mathbb{C}_{\alpha}, \tau)$-differentially individually fair. Let $G$ be an indicator set in $\mathbb{C}_{\alpha}$. Let $\pi$ be an assignment from $\mathfrak{A}$ to $\mathfrak{A}$. Fix a protected value $a\in \mathfrak{A}$ and construct  the reassignment $\sigma$ such that for all $u\in \mathfrak{A}$, $\sigma(u)=a$. Therefore,
 
\begin{equation}
\begin{split}
    E_{x^{*}\sim G}\left[\left|f(x^{*}) - f(x^{*}_{\pi})\right|\right]  & = E_{(x^{*}, x_{2}^{*})\sim G \times G}\left[\left|f(x^{*}) - f(x^{*}_{\pi})\right|\right] \\
    & \leq  \tau +  E_{(x^{*}, x_{2}^{*})\sim G \times G}\left[\left|f(x^{*}_{\sigma}) - f(x^{*}_{\sigma\pi})\right|\right]  \\
    & \leq \tau,
    \end{split}
\end{equation}
since $x^{*}_{\sigma} = x^{*}_{\sigma\pi}$

\subsection{Proof of theorem \ref{thm: mf}}
Let $S\in \mathfrak{C}$. There exists $G\in \mathbb{C}$ such that $(x,x^{'})\in S$ if and only if $x, x^{'}\in G$. For $(x,a), (x^{'}, a^{'})\sim S$, 
\begin{equation}
    \left|f(x,a) - f(x^{'}, a^{'})\right| = \frac{1}{|\mathbb{A}|}\left|\displaystyle\sum_{u\in \mathbb{A}} f(x,a) - f(x,u) + \displaystyle\sum_{u\in \mathbb{A}} f(x^{'},u) - f(x^{'},a^{'}) + \displaystyle\sum_{u\in \mathbb{A}} f(x,u) - f(x^{'},u)\right|
\end{equation}

Moreover, since $f$ is $(\mathbb{C}, \beta)$-metric free individual fair,
\begin{equation}
\begin{split}
    E_{(x,a), (x^{'}, a^{'})\sim S}\left[\frac{1}{|\mathbb{A}|}\left|\displaystyle\sum_{u\in \mathbb{A}} f(x,a) - f(x,u)\right|\right] &= E_{x\sim G}\left[\frac{1}{|\mathbb{A}|}\left|\displaystyle\sum_{u\in \mathbb{A}} f(x,a) - f(x,u)\right|\right] \\
    & \leq \frac{1}{|\mathbb{A}|}\displaystyle\sum_{u\in \mathbb{A}} E_{x\sim G} \left[\left |f(x,a) - f(x,u)\right|\right] \\
    & \leq \beta.
    \end{split}
\end{equation}

\begin{equation}
\begin{split}
    E_{(x,a), (x^{'}, a^{'})\sim S}\left[|f(x,a) -f(x^{'}, a^{'})|\right]&\leq 2\beta +  \frac{1}{|\mathbb{A}|}\displaystyle\sum_{u\in \mathbb{A}}E_{(x,a), (x^{'}, a^{'})\sim S}\left[\left|  f(x,u) - f(x^{'},u)\right|\right]\\
    & \leq 2\beta + \frac{1}{|\mathbb{A}|}\displaystyle\sum_{u\in \mathbb{A}}E_{(x, x^{'})\sim S}\delta(x, x^{'}) \\
    & \leq 2\beta + E_{(x, x^{'})\sim S}\delta(x, x^{'}).
    \end{split}
\end{equation}

\subsection{Proof of PAC Reduction}

Suppose first that there exists an auditing algorithm $\mathfrak{M}(\epsilon, \delta)$ which audits in time $poly(1/\delta, 1/epsilon)$ for metric-free individual fairness using a concept class $\mathbb{C}$. Denote $(x, b)$ a draw from $P$. Denote $c^{*}\in \mathbb{C}$ an indicator $c^{*}: \mathfrak{X} \rightarrow \{-1,1\}$ Let $D$ denote a distribution over $\mathfrak{X}$ and $P=\{(x, c^{*}(x))| x\sim D\}$ the corresponding distribution over $\mathfrak{X}\times [-1,1]$. 

\bigskip
Consider a sample $S$ of $m$ examples of $P$, with $m$ to be determined later on. Construct $f$ such that

\begin{equation}
    f(x, a) = \begin{cases}
    -c(x) & \mbox{ if } c(x)=1 \mbox{ and } (x, c(x))\in S  \\
    1 & \mbox{otherwise }.
    \end{cases}
\end{equation}

Consider the following reassignment of protected attributes: fix $a^{'}\in \mathfrak{A}$ with $a^{'}\neq 0$.
\begin{equation}
    \pi(a) = \begin{cases}
    a^{'} & \mbox{ if } a=0  \\
    0 & \mbox{if } a\neq 0.
    \end{cases}
\end{equation}

Let $U_{S}$ denote the uniform distribution on $S$. Oracle access $EX(f, U_{S})$ and local membership access $MQ(f, \pi)$ can be simulated from $S$. Therefore, the auditing algorithm $\mathfrak{M}(\epsilon, \delta)$ can be applied on $U_{S}$ to audit the classifier $f$. Denote $u_{\pi}(x)=|f(x)-f_{\pi}(x)| -1$. Since $c^{*}=u_{\pi}$ and $\langle c, u_{\pi}\rangle =1$, there exists $h\in \mathbb{H}$ such that $$\langle h, c\rangle(S) \geq 1 -2\epsilon/3.$$ 

\bigskip
Denote $d$ the VC dimension of $\mathbb{H}\cup\mathbb{C}$. Then, by uniform convergence, if $$m=O\left(\frac{9}{4}\frac{d\log(2d/(3\epsilon)) + \log(1/\delta)}{\epsilon^{2}}\right),$$
with probability $1-\delta$
$$|\langle c, b\rangle(S) - \langle c, b\rangle(P)| \leq 2\frac{\epsilon}{3} $$

and

$$|\langle h, b\rangle(S) - \langle h, b\rangle(P)| \leq 2\frac{\epsilon}{3}. $$
Therefore,

$$Pr[h=c^{*}]=\frac{\langle h, u_{\pi}\rangle(P) + 1}{2} \geq \frac{\langle h, u_{\pi}\rangle(S)+ 1}{2} - 2\frac{\epsilon}{3}\geq \langle c^{*}, b\rangle(S) - 2\frac{\epsilon}{3}\geq \langle c^{*}, b\rangle(P) - \epsilon.$$
Morevoer, $h$ is output in $poly(1/\epsilon, 1/\delta) + O\left(\frac{d\log(d/(\epsilon)) + \log(1/\delta)}{\epsilon^{2}}\right)$.

\bigskip
Conversely, assume that $\mathbb{C}$ is PAC learnable by $\mathbb{H}$ in $poly(1/\epsilon, 1/\delta)$. Let $f$ be a classifier defined on $\mathfrak{X}$ and $D$ be a distribution over $\mathfrak{X}$.  Let $\pi$ be a reassignment of protected attributes. Let $u_{\pi}$ denote the function $u_{\pi}(x)=2|f(x) -f_{\pi}(x)| - 1$. Denote $P$ the distribution induced by $u_{\pi}$: $P=\{(x, u_{\pi}(x)) | x\sim D\}$. Suppose that $f$ is $(\mathbb{C}_{\alpha}, \beta)$-unfair. Therefore, there exists $c\in\mathbb{C}$ such that $Pr[c=1] \geq \alpha$ and  $\langle c, u_{\pi}\rangle (P) \geq 2\beta -\alpha$.  Since $\mathbb{C}$ is PAC learnable by $\mathbb{H}$, there exists $h\in \mathbb{H}$ such that 

$$ Pr[h=c] \geq 1- \epsilon$$ and such a $h$ is obtained in $poly(1/\epsilon, 1/\delta).$ Moreover, 

\begin{equation}
\begin{split}
    1 &\geq Pr[h=c] + Pr[c=u_{\pi}] - Pr[(h=c) \; \& \; (c=u_{\pi})] \geq 1-\epsilon + \frac{\langle c, u_{\pi}\rangle + 1}{2} \\
    & \geq 1-\epsilon + \frac{2\beta -\alpha + 1}{2}- Pr[(h=c) \; \& \; (c=u_{\pi})] .
    \end{split}
\end{equation}
Therefore,

$$  \frac{\langle h, u_{\pi}\rangle + 1}{2} =Pr[h=u_{\pi}] \geq Pr[(h=c) \; \& \; (c=u_{\pi})] \geq \frac{2\beta -\alpha + 1}{2} - \epsilon,$$
which implies 

$$\langle h, u_{\pi}\rangle  \geq 2\beta -\alpha -2 \epsilon.$$

Moreover $Pr[h=1]\geq Pr[c=1]-\epsilon\geq \alpha -\epsilon$. Therefore, with probability $1-\delta$, if $f$ is $(\alpha, \beta)$ unfair, the algorithm $\mathfrak{M}(\delta, \epsilon)$ outputs a $(\alpha-\epsilon, \beta-\epsilon)$ unfairness certificate. 

\bigskip
Suppose now that $f$ is $(\mathbb{C}_{\alpha}, \beta)$ metric free individually fair. Then for all $c\in \mathbb{C}$ with $Pr[c=1]\geq 1$, $\langle c, u_{\pi}\rangle \leq 2\beta -\alpha,$ where is $u_{\pi}$ is defined as above. Consider $c$ in  $c\in \mathbb{C}$. By PAC learning, algorithm $\mathfrak{M}(\epsilon, \delta)$ delivers with probability $1-\delta$ a $h\in \mathbb{H}$ such that $Pr[h=c]\geq 1-\epsilon.$ Therefore, $Pr[h=1] \geq \alpha -\epsilon$ and 

$$\langle h, u_{\pi}\rangle =  2 Pr[h=u_{\pi}] -1 \leq 2Pr[c=u_{\pi}] - 1 + 2\epsilon  = \langle c, u_{\pi} \rangle + 2\epsilon \leq 2\beta -\alpha + 2\epsilon.$$
Therefore, algorithm $\mathfrak{M}(\epsilon, \delta)$ will guarantee with probability $1-\delta$ that $f$ is $(\alpha-\epsilon, \beta + \epsilon)$ metric-free individually fair. 


\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{references}

\end{document}