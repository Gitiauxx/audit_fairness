{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('notebook')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll suppress warnings because both altair and sklearn are\n",
    "# emitting lots of them, and they're annoying in a demo setting.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import altair as alt\n",
    "# Ask Altair to produce output that works on Jupyter Notebook\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness.algorithms.Algorithm import Algorithm\n",
    "import pandas as pd\n",
    "\n",
    "# Simple example that rebalances the training set wrt to the sensitive attribute\n",
    "# to mitigate balancing problems, and uses any baseline SKLearn algorithm for prediction\n",
    "\n",
    "# NB: This isn't a remotely good algorithm! \n",
    "#     But it's very simple to implement and gets the point across.\n",
    "\n",
    "class SensitiveAttrRebalancing(Algorithm):\n",
    "    def __init__(self, algorithm, baseline_name):\n",
    "        # the only field you must initialize here is \"name\", which needs to be a\n",
    "        # unique string that will be used to identify this algorithm in the\n",
    "        # result data frames\n",
    "        Algorithm.__init__(self)\n",
    "        self.classifier = algorithm\n",
    "        self.name = \"SensitiveAttrRebalancing\" + baseline_name\n",
    "        \n",
    "    def run(self, train_df, test_df, class_attr, positive_class_val, sensitive_attrs,\n",
    "            single_sensitive, privileged_vals, params):\n",
    "        # - train_df is a pandas dataframe with the training data\n",
    "        # - test_df is a pandas dataframe with the testing data\n",
    "        # - class_attr is the attribute to be predicted\n",
    "        # - positive_class_value is the assumed \"good\" prediction, which might\n",
    "        #   be necessary information for some methods\n",
    "        # - sensitive_attrs is a list of the columns that are considered sensitive\n",
    "        #   attributes for the sake of fairness\n",
    "        \n",
    "        # - single_sensitive is a the name of the sensitive attribute\n",
    "        #   being handled in this run\n",
    "        # - privileged_vals is a list of values (one per sensitive attribute)\n",
    "        #   considered \"privileged\", which is necessary for one-sided definitions\n",
    "        #   of discrimination\n",
    "        # - params: a description of the hyperparameters being used for the current run\n",
    "        \n",
    "        # for sake of simplicity, we only support datasets with\n",
    "        # a single sensitive attribute        \n",
    "        priv_val = privileged_vals[sensitive_attrs.index(single_sensitive)]\n",
    "        total = len(train_df)\n",
    "        \n",
    "        train_priv     = train_df[train_df[single_sensitive] == priv_val]\n",
    "        train_non_priv = train_df[train_df[single_sensitive] != priv_val]\n",
    "        \n",
    "        train_priv_balance     = train_priv.sample(n=int(total/2), replace=True)\n",
    "        train_non_priv_balance = train_non_priv.sample(n=int(total/2), replace=True)\n",
    "        \n",
    "        train_df = pd.concat([train_priv_balance, train_non_priv_balance])\n",
    "        \n",
    "\n",
    "        # remove sensitive attributes from the training set\n",
    "        train_df_nosensitive = train_df.drop(columns = sensitive_attrs)\n",
    "        test_df_nosensitive = test_df.drop(columns = sensitive_attrs)\n",
    "\n",
    "        # create and train the classifier\n",
    "        classifier = self.classifier()\n",
    "        y = train_df_nosensitive[class_attr]\n",
    "        X = train_df_nosensitive.drop(columns = class_attr)\n",
    "        classifier.fit(X, y)\n",
    "\n",
    "        # get the predictions on the test set\n",
    "        X_test = test_df_nosensitive.drop(class_attr, axis=1)\n",
    "        predictions = classifier.predict(X_test)\n",
    "        print(predictions)\n",
    "\n",
    "        return predictions, []\n",
    "\n",
    "    def get_supported_data_types(self):\n",
    "        # There are currently four types of possible data types:\n",
    "        #  - numerical\n",
    "        #  - numerical-binsensitive\n",
    "        #  - categorical\n",
    "        #  - categorical-binsensitive\n",
    "        #\n",
    "        # a \"numerical\" datatype is one in which every column is numerical. If your algorithm\n",
    "        # only supports numerical values (like an SVM or LR), then use \"numerical-*\" options\n",
    "        #\n",
    "        # a \"-binsensitive\" suffix refers to the fact that the sensitive attribute must be binary.\n",
    "        # If your algorithm supports more than binary sensitive attributes, then you can\n",
    "        # return \"categorical\" or \"numerical\" in this method.\n",
    "        #\n",
    "        # For the sake of simplicity, we use only the simplest option, \"numerical-binsensitive\".\n",
    "        # In this case, the `fairness` package binarizes the sensitive attribute (but do note this\n",
    "        # introduces potential problems with intersectionality, see Buolamwini and Gebru's 2018 FAT*\n",
    "        # paper for a clear example).\n",
    "        return set([\"numerical-binsensitive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairness\n",
    "import fairness.benchmark\n",
    "from sklearn.tree import DecisionTreeClassifier as SKLearn_DT\n",
    "\n",
    "fairness.add_algorithm(SensitiveAttrRebalancing(SKLearn_DT, \"DecisionTree\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: '['heart-disease_numerical-binsensitive']'\n"
     ]
    }
   ],
   "source": [
    "fairness.benchmark.run(algorithm=[\"SensitiveAttrRebalancingDecisionTree\"], dataset=[\"heart-disease_numerical-binsensitive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No dataset with name heart-disease_numerical-binsensitive could be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e73207bd5ef6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mricci_Race\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfairness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"heart-disease_numerical-binsensitive\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_results_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sex\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"numerical-binsensitive\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mricci_Race\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mricci_Race\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mricci_Race\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DecisionTree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m alt.Chart(ricci_Race).mark_point().encode(\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'DIbinary'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda36\\lib\\site-packages\\fairness\\data\\objects\\list.py\u001b[0m in \u001b[0;36mget_dataset_by_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No dataset with name %s could be found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: No dataset with name heart-disease_numerical-binsensitive could be found."
     ]
    }
   ],
   "source": [
    "ricci_Race = fairness.get_dataset_by_name(\"heart-disease_numerical-binsensitive\").get_results_data_frame(\"Sex\", \"numerical-binsensitive\")\n",
    "ricci_Race = ricci_Race[ricci_Race.algorithm.str.contains(\"DecisionTree\")]\n",
    "alt.Chart(ricci_Race).mark_point().encode(\n",
    "    x='accuracy',\n",
    "    y='DIbinary',\n",
    "    color='algorithm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
